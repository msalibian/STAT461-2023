{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to M-estimators\n",
    "\n",
    "#### LICENSE\n",
    "These notes are released under the \n",
    "\"Creative Commons Attribution-ShareAlike 4.0 International\" license. \n",
    "See the **human-readable version** [here](https://creativecommons.org/licenses/by-sa/4.0/)\n",
    "and the **real thing** [here](https://creativecommons.org/licenses/by-sa/4.0/legalcode). \n",
    "\n",
    "#### INSTALLATION instructions\n",
    "\n",
    "To use this noteboook you may need to install a few packages in `R`:\n",
    "```\n",
    "install.packages(c('rmutil', 'robustbase', 'RobStatTM'))\n",
    "```\n",
    "\n",
    "## Intro\n",
    "\n",
    "In this notebook we will review simple location M-estimators, some of their \n",
    "robustness properties, and algorithms to compute them. \n",
    "\n",
    "We first start by loading a simple data set `robustbase::cushny`. Refer to \n",
    "`help(cushny, package='robustbase')` for information on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x <- robustbase::cushny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good idea to look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boxplot(x, col='tomato3', cex=1.5, pch=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rbind(mean = mean(x), median = median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute an M-estimator, using a Huber loss, and without standardizing. We \n",
    "write our own code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huberPsi <- function(r, cc)\n",
    "    return( pmin(pmax(-cc, r), cc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mest0 <- function(x, cc=1.345, init=median(x), max.it = 100, eps=1e-8) {\n",
    "    m1 <- init\n",
    "    m0 <- m1 + 10*eps\n",
    "    it <- 0\n",
    "    while( ((it <- it+1) < max.it ) & (abs(m1-m0) > eps ) ) {\n",
    "        re <- (x - m1)\n",
    "        w <- huberPsi(re, cc=cc)/re\n",
    "        w[ is.na(w) ] <- 1\n",
    "        m0 <- m1\n",
    "        m1 <- sum( x*w ) / sum(w)\n",
    "    }\n",
    "    return(m1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the M-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu0 <- mest0(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and verify that it is \"between\" the mean and the median. We can also check that it is correctly computed (sanity check): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean( huberPsi(x-mu0, cc=1.345)) # this should be essentially zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lack of scale invariance, robustness\n",
    "\n",
    "As we discussed in class, this estimator is not scale equivariant. For example, if we divide all the data by 100, and then multiply the resulting estimator by 100, we do not recover the original estimator. In fact, something much more \"surprising\" happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rbind(mean=c(mean(x), mean(x/100)*100),\n",
    "      median=c(median(x), median(x/100)*100),\n",
    "      Mest=c(mest0(x), mest0(x/100)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The suppossedly robust M-estimator computed on the \"scaled\" data is identical to the sample mean! This is a serious problem, as the estimator is not robust any longer. As discussed in class, the problem is that the tuning parameter (the choice of loss function rho depends on the \"size\" of the data / residuals). \n",
    "\n",
    "We now add 2 outliers to illustrate that this non-scale-equivariant M-estimator really is not robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xc <- c(x, rnorm(2, mean=5.5, sd=.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the estimators again. Note that the performance of the M-estimator deteriorates (it appears to be affected by the outliers), but not as much as the sample mean.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rbind(mean=c(mean(x), mean(xc)),\n",
    "      median=c(median(x), median(xc)),\n",
    "      Mest=c(mest0(x), mest0(xc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To again illustrate the problem of the relative magnitudes of the data and the tuning constant of the (hopefully) robust loss, we compute the estimators on \"proportionally smaller\" data, and then re-scale it back to the original units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rbind(mean=c(mean(x), mean(xc), mean(xc/100)*100),\n",
    "      median=c(median(x), median(xc), median(xc/100)*100),\n",
    "      Mest=c(mest0(x), mest0(xc), mest0(xc/100)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can clearly see the deterioration of the M-estimator. It is just not working well. \n",
    "\n",
    "## Using scaled residuals helps in choosing the robust loss\n",
    "\n",
    "The solution, as we discussed in more detail in class, is to use standardized residuals. The only difference between the \"good\" M-estimator computed with `mest` below and the previous one (`mest0`) is the inclusion of the robust scale estimator (`si <- mad(x)`), and its use in the computation of residuals (`re <- (x - m1) / si`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mest <- function(x, cc=1.345, init=median(x), si = mad(x), max.it = 100, eps=1e-8) {\n",
    "    m1 <- init\n",
    "    m0 <- m1 + 10*eps\n",
    "    it <- 0\n",
    "    while( ((it <- it+1) < max.it ) & (abs(m1-m0) > eps ) ) {\n",
    "        re <- (x - m1) / si\n",
    "        w <- huberPsi(re, cc=cc)/re\n",
    "        w[ is.na(w) ] <- 1\n",
    "        m0 <- m1\n",
    "        m1 <- sum( x*w ) / sum(w)\n",
    "    }\n",
    "    return(m1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now everything works fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rbind(mean=c(mean(x), mean(xc), mean(xc/100)*100),\n",
    "      median=c(median(x), median(xc), median(xc/100)*100),\n",
    "      Mest=c(mest(x), mest(xc), mest(xc/100)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check again. First order conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si <- mad(xc)\n",
    "mu1 <- mest(xc)\n",
    "mean( huberPsi((xc-mu1)/si, cc=1.345))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M-estimators are robust, not immutable\n",
    "\n",
    "Note, however, that the M-estimator is in fact, affected by the outliers. Fortunately, this effect is bounded, and will not get any worse even if the outliers were much more extreme. For example, if the outliers were placed at `+20` (instead of `5.5`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xc2 <- c(x, rnorm(2, mean=20, sd=.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... then the M-estimator does not shift any further to the right, as opposed to what happens with the sample mean: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rbind(mean=c(mean(x), mean(xc), mean(xc2)),\n",
    "      median=c(median(x), median(xc), median(xc2)),\n",
    "      Mest=c(mest(x), mest(xc), mest(xc2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
