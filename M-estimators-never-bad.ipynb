{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LICENSE\n",
    "These notes are released under the \n",
    "\"Creative Commons Attribution-ShareAlike 4.0 International\" license. \n",
    "See the **human-readable version** [here](https://creativecommons.org/licenses/by-sa/4.0/)\n",
    "and the **real thing** [here](https://creativecommons.org/licenses/by-sa/4.0/legalcode). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INSTALLATION instructions\n",
    "\n",
    "To use this noteboook you may need to install a few packages in `R`:\n",
    "```\n",
    "install.packages(c('rmutil', 'robustbase', 'RobStatTM'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M-estimators are generally very close to being optimal\n",
    "\n",
    "Although M-estimators are generally not optimal, they are often \"quite good\", and rarely \"bad\".\n",
    "Here we illustrate this with simple numerical experiments.\n",
    "\n",
    "\n",
    "\n",
    "Note that the good properties of the sample mean as\n",
    "an estimator for the population mean only hold under\n",
    "strict distributional assumptions. Even for symmetric\n",
    "errors, the sample mean may be highly inefficient \n",
    "(high variance). \n",
    "For example, if the errors have heavier tails than \n",
    "gaussian (double exponential, say), then the sample\n",
    "mean can perform significantly worse than the MLE\n",
    "(which, for the Laplace / double exponential case,\n",
    "is the sample median). \n",
    "\n",
    "Robust estimators try to find estimation methods that\n",
    "perform well in a variety of situations, will typically\n",
    "not be optimal, but will generally be good enough. \n",
    "\n",
    "The code below contains simple Monte Carlo experiments\n",
    "comparing the efficiency (MSE) of 4 natural estimators:\n",
    "the sample mean, the sample median (which is the\n",
    "MLE in this case), and two M-estimators: \n",
    "the estimator labelled `monotoneM` is the M-estimator with\n",
    "Huber's non-decreasing `psi` function `pmax(pmin(t, k), -k)`, while\n",
    "the `redecsM` one uses a `psi` function that is zero for large \n",
    "residuals. We will discuss this function in more detail next week.\n",
    "\n",
    "We consider\n",
    "10,000 samples of size 50, and compare the corresponding Monte Carlo \n",
    "MSEs.\n",
    "\n",
    "#### Laplace errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages(library(rmutil))\n",
    "n <- 50\n",
    "M <- 10000\n",
    "set.seed(123)\n",
    "x <- matrix(rlaplace(n*M), M, n)\n",
    "mus <- rowMeans(x)\n",
    "meds <- apply(x, 1, median)\n",
    "# M-estimators\n",
    "monm <- apply(x, 1, function(a) robustbase::huberM(a, k = 1.345)$mu )\n",
    "redm <- apply(x, 1, function(a) RobStatTM::locScaleM(a, psi='bisquare')$mu )\n",
    "MSE.means <- mean( mus^2 )\n",
    "MSE.medians <- mean( meds^2 )\n",
    "MSE.monotoneM <- mean( monm^2 )\n",
    "MSE.redescM <- mean( redm^2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(rbind(MSE.means = MSE.means, MSE.medians= MSE.medians,\n",
    "  MSE.monotoneM = MSE.monotoneM, MSE.redescM = MSE.redescM ), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(rbind(eff.means = MSE.medians / MSE.means, \n",
    "            eff.medians = MSE.medians / MSE.medians, \n",
    "            eff.monotoneM = MSE.medians / MSE.monotoneM, \n",
    "            eff.redescM = MSE.medians / MSE.redescM), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the M-estimators do much better than the sample mean, \n",
    "and fairly close to the optimal MLE. \n",
    "\n",
    "#### Gaussian errors (M- vs MLE(mean))\n",
    "\n",
    "It is easy to see then when the sample mean is the optimal\n",
    "estimator (for example, when the errors are Gaussian), the\n",
    "M-estimators again behave very similarly to the optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "n <- 50\n",
    "M <- 10000\n",
    "set.seed(123)\n",
    "x <- matrix(rnorm(n*M), M, n)\n",
    "mus <- rowMeans(x)\n",
    "meds <- apply(x, 1, median)\n",
    "# M-estimators\n",
    "monm <- apply(x, 1, function(a) robustbase::huberM(a, k = 1.345)$mu )\n",
    "redm <- apply(x, 1, function(a) RobStatTM::locScaleM(a, psi='bisquare')$mu )\n",
    "MSE.means <- mean( mus^2 )\n",
    "MSE.medians <- mean( meds^2 )\n",
    "MSE.monotoneM <- mean( monm^2 )\n",
    "MSE.redescM <- mean( redm^2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(rbind(MSE.means = MSE.means, MSE.medians= MSE.medians,\n",
    "  MSE.monotoneM = MSE.monotoneM, MSE.redescM = MSE.redescM ), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(rbind(eff.means = MSE.means / MSE.means, \n",
    "            eff.medians = MSE.means / MSE.medians, \n",
    "            eff.monotoneM = MSE.means / MSE.monotoneM, \n",
    "            eff.redescM = MSE.means / MSE.redescM), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T4 errors (M- vs MLE)\n",
    "\n",
    "We repeat the experiment with Student's T errors (df = 4),\n",
    "and include the MLE estimator. The conclusion is the same as\n",
    "above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "options(warn = -1) # remove all warning messages\n",
    "n <- 100\n",
    "M <- 5000\n",
    "set.seed(123)\n",
    "x <- matrix(rt(n*M, df=4), M, n)\n",
    "mus <- rowMeans(x)\n",
    "meds <- apply(x, 1, median)\n",
    "mles <- apply(x, 1, function(a) MASS::fitdistr(a, 't', df=4)$estimate[1] )\n",
    "# M-estimators\n",
    "monm <- apply(x, 1, function(a) robustbase::huberM(a, k = 1.345)$mu )\n",
    "redm <- apply(x, 1, function(a) RobStatTM::locScaleM(a, psi='bisquare')$mu )\n",
    "MSE.means <- mean( mus^2 )\n",
    "MSE.medians <- mean( meds^2 )\n",
    "MSE.monotoneM <- mean( monm^2 )\n",
    "MSE.redescM <- mean( redm^2 )\n",
    "MSE.mles <- mean(mles^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(rbind(MSE.means = MSE.means, MSE.medians= MSE.medians,\n",
    "            MSE.mles = MSE.mles, MSE.monotoneM = MSE.monotoneM, \n",
    "            MSE.redescM = MSE.redescM ), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(rbind(eff.means = MSE.mles / MSE.means, \n",
    "            eff.medians = MSE.mles / MSE.medians, \n",
    "            eff.mles = MSE.mles / MSE.mles,\n",
    "            eff.monotoneM = MSE.mles / MSE.monotoneM, \n",
    "            eff.redescM = MSE.mles / MSE.redescM), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gross error oultiers (\"point contamination\") (M- vs all)\n",
    "\n",
    "Finally, if we use a \"gross error\"-type departure from a T-4 model, \n",
    "the results are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn = -1) # remove all warning messages\n",
    "n <- 100\n",
    "M <- 5000\n",
    "set.seed(123)\n",
    "generate <- function(n, epsilon, x0) {\n",
    "  tmp <- rbinom(n, size=1, prob=epsilon)\n",
    "  x <- rt(n, df=4)\n",
    "  x[ tmp == 1 ] <- rnorm(sum(tmp), mean=x0, sd=1)\n",
    "  return(x)\n",
    "}\n",
    "x <- matrix(NA, M, n)\n",
    "set.seed(321)\n",
    "for(i in 1:M) x[i,] <- generate(n=n, x0=8, epsilon=.1) \n",
    "mus <- rowMeans(x)\n",
    "meds <- apply(x, 1, median)\n",
    "mles <- apply(x, 1, function(a) MASS::fitdistr(a, 't', df=4)$estimate[1] )\n",
    "# M-estimators\n",
    "monm <- apply(x, 1, function(a) robustbase::huberM(a, k = 1.345)$mu )\n",
    "redm <- apply(x, 1, function(a) RobStatTM::locScaleM(a, psi='bisquare')$mu )\n",
    "MSE.means <- mean( mus^2 )\n",
    "MSE.medians <- mean( meds^2 )\n",
    "MSE.monotoneM <- mean( monm^2 )\n",
    "MSE.redescM <- mean( redm^2 ) \n",
    "MSE.mles <- mean(mles^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "round(rbind(MSE.means = MSE.means, MSE.medians= MSE.medians,\n",
    "            MSE.mles = MSE.mles, MSE.monotoneM = MSE.monotoneM, \n",
    "            MSE.redescM = MSE.redescM ), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "round(rbind(acc.means = MSE.mles / MSE.means, \n",
    "            acc.medians = MSE.mles / MSE.medians, \n",
    "            acc.mles = MSE.mles / MSE.mles,\n",
    "            acc.monotoneM = MSE.mles / MSE.monotoneM, \n",
    "            acc.redescM = MSE.mles / MSE.redescM), 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
