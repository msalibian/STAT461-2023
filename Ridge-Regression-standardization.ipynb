{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LICENSE\n",
    "These notes are released under the \n",
    "\"Creative Commons Attribution-ShareAlike 4.0 International\" license. \n",
    "See the **human-readable version** [here](https://creativecommons.org/licenses/by-sa/4.0/)\n",
    "and the **real thing** [here](https://creativecommons.org/licenses/by-sa/4.0/legalcode). \n",
    "\n",
    "## Ridge regression \n",
    "\n",
    "### Standardizing  responses and explanatory variables\n",
    "\n",
    "As we discussed in class (also see the course notes) \n",
    "penalty terms in regularized linear regression estimators do not typically include the intercept\n",
    "(if one if present). Furthemore, unless the covariates are\n",
    "standardized (e.g. to all have the same norm), the \n",
    "the magnitude of the regularization (penalization)\n",
    "may depend on the scale of the covariates. For example, \n",
    "the scale of any one feature (which is \n",
    "arbitrary and can be modified without changing the model) \n",
    "may radically change the final level of \"shrinkage\"\n",
    "or regularization. \n",
    "\n",
    "Here we illustrate this issue with a simple example. \n",
    "\n",
    "First, load the `alcohol` data, and set up the \"design matrix\" `x`\n",
    "and the response variable `y` for use with `glmnet`. We will use\n",
    "`glmnet()` with `alpha = 0` to compute a Ridge Regression estimator,\n",
    "and choose an optimal level of penalization via the default\n",
    "5-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "message": "FALSE",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "data(alcohol, package='robustbase')\n",
    "\n",
    "x <- model.matrix(logSolubility ~ ., data=alcohol)\n",
    "x <- x[, -1]\n",
    "y <- alcohol$logSolubility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set up a (rather wide) grid of possible values for the penalization\n",
    "constant, and use `cv.glmnet()` to explore the prediction properties of\n",
    "the corresponding fits. We will select the value of lambda (the penalty\n",
    "parameter) with smallest\n",
    "CV criterion. \n",
    "\n",
    "We will force `glmnet` to not standardize our data (use the\n",
    "argument `standardize = FALSE`), and report the vector of estimated\n",
    "regression coefficients for that optimal value of lambda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "message": "FALSE",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "lambdas <- exp( seq(-20, 10, length=200))\n",
    "set.seed(123)\n",
    "a <- cv.glmnet(x=x, y=y, family='gaussian', alpha=0, lambda=lambdas, standardize = FALSE)\n",
    "a$lambda.min\n",
    "round(coef(a, s='lambda.min'), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate our point, we now change the scale of one of the covariates (`RM`), \n",
    "repeat our Ridge Regression fit and compare the results. \n",
    "\n",
    "We would, naturally, like that the amount of regularization only changes \n",
    "(proportionally) for the modified covariate, but that the rest of the \n",
    "fit model remains the same. Alas, this is not to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "message": "FALSE",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "x[, 5] <- x[, 5] / 100000\n",
    "set.seed(123)\n",
    "b <- cv.glmnet(x=x, y=y, family='gaussian', alpha=0, lambda=lambdas, standardize = FALSE)\n",
    "b$lambda.min\n",
    "round(cbind(coef(a, s='lambda.min'), coef(b, s='lambda.min')), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the CV curves can change quite dramatically as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "message": "FALSE",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "message": "FALSE",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "plot(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default behaviour of `glmnet` is to fit the model on properly standardized variables,\n",
    "and then re-express them in the original scale. Thus, the results are appropriately \n",
    "equivariant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "message": "FALSE",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "### w/standardization\n",
    "x <- model.matrix(logSolubility ~ ., data=alcohol)\n",
    "x <- x[, -1]\n",
    "y <- alcohol$logSolubility\n",
    "set.seed(123)\n",
    "a2 <- cv.glmnet(x=x, y=y, family='gaussian', alpha=0, lambda=lambdas, standardize = TRUE)\n",
    "x[, 5] <- x[, 5] / 100000\n",
    "set.seed(123)\n",
    "b2 <- cv.glmnet(x=x, y=y, family='gaussian', alpha=0, lambda=lambdas, standardize = TRUE)\n",
    "round(cbind(coef(a2, s='lambda.min'), coef(b2, s='lambda.min')), 4)\n",
    "c(a2$lambda.min, b2$lambda.min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the CV curves are also identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "message": "FALSE",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "plot(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "message": "FALSE",
     "warning": "FALSE,"
    }
   },
   "outputs": [],
   "source": [
    "plot(b2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
